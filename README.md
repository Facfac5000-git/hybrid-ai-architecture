# Arquitectura HÃ­brida Extensible para Sistemas IA-Ready

Una implementaciÃ³n prÃ¡ctica de la arquitectura hÃ­brida propuesta en el paper acadÃ©mico "Una Arquitectura HÃ­brida Extensible para Sistemas IA-Ready" por Facundo Leonardo Chayle.

## ğŸ—ï¸ Arquitectura

### Componentes Principales

- **Orchestration Service** (NestJS): Servicio principal de orquestaciÃ³n y lÃ³gica de negocio
- **AI Service** (FastAPI): Microservicio especializado en procesamiento inteligente
- **Edge Agent** (FastAPI): Agente opcional para inferencia local de baja latencia
- **Redis**: CachÃ© y comunicaciÃ³n asÃ­ncrona
- **Nginx**: Load balancer y reverse proxy (producciÃ³n)
- **Prometheus + Grafana**: Monitoreo y mÃ©tricas (opcional)

### CaracterÃ­sticas Implementadas

âœ… **OrquestaciÃ³n DinÃ¡mica**: SelecciÃ³n contextual entre cloud y edge  
âœ… **Zero Trust AI**: ValidaciÃ³n rigurosa de entrada/salida  
âœ… **MÃºltiples Modelos**: Soporte para diferentes modelos de IA  
âœ… **Logging Estructurado**: Trazabilidad completa con request IDs  
âœ… **Health Checks**: Monitoreo de salud de servicios  
âœ… **ValidaciÃ³n Pydantic**: Schemas robustos con sanitizaciÃ³n  
âœ… **MÃ©tricas de Performance**: Tiempos de inferencia y estadÃ­sticas  

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- Docker y Docker Compose
- Node.js 18+ (para desarrollo local)
- Python 3.11+ (para desarrollo local)
- Poetry (para gestiÃ³n de dependencias Python)

### ConfiguraciÃ³n

1. **Clonar el repositorio**
```bash
git clone https://github.com/Facfac5000-git/hybrid-ai-architecture.git
cd hybrid-ai-architecture
```

2. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env segÃºn necesidades
```

3. **Ejecutar con Docker Compose**

**Desarrollo (servicios bÃ¡sicos):**
```bash
docker-compose -f docker-compose.dev.yml up --build
```

**ProducciÃ³n (todos los servicios):**
```bash
docker-compose up --build
```

**Con Edge Agent:**
```bash
docker-compose --profile edge up --build
```

**Con Monitoreo:**
```bash
docker-compose --profile monitoring up --build
```

### Endpoints Principales

- **Orchestration Service**: http://localhost:3000
  - `POST /procesar-tarea` - Procesamiento de tareas
  - `GET /health` - Health check

- **AI Service**: http://localhost:8000
  - `POST /predict` - PredicciÃ³n de IA
  - `GET /stats` - EstadÃ­sticas del servicio
  - `GET /models` - Modelos disponibles
  - `GET /health` - Health check

- **Edge Agent**: http://localhost:8001 (opcional)
  - `POST /predict` - PredicciÃ³n edge
  - `GET /health` - Health check

## ğŸ”§ Desarrollo Local

### AI Service (FastAPI)

```bash
cd ai_service
poetry install
poetry run uvicorn app.main:app --reload --port 8000
```

### Orchestration Service (NestJS)

```bash
cd orchestration_service
npm install
npm run start:dev
```

### Edge Agent (FastAPI)

```bash
cd edge_agent
poetry install
poetry run uvicorn app.main:app --reload --port 8001
```

## ğŸ“Š Monitoreo

### Prometheus
- URL: http://localhost:9090
- MÃ©tricas de aplicaciÃ³n y sistema

### Grafana
- URL: http://localhost:3001
- Usuario: admin
- ContraseÃ±a: admin123

## ğŸ§ª Testing y ValidaciÃ³n

### Estado Actual: âœ… ARQUITECTURA COMPLETAMENTE FUNCIONAL

La arquitectura hÃ­brida ha sido probada exitosamente end-to-end con todos los componentes operativos.

### Comandos de Prueba Validados

#### 1. OrquestaciÃ³n DinÃ¡mica (Endpoint Principal)
```bash
# Procesar tarea a travÃ©s del orquestador - Demuestra orquestaciÃ³n inteligente
curl -X POST http://localhost:3000/procesar-tarea \
  -H "Content-Type: application/json" \
  -d '{
    "entrada": "Necesito procesar esta tarea urgente",
    "contexto": "Procesamiento de alta prioridad"
  }'

# Respuesta esperada: DecisiÃ³n automÃ¡tica entre cloud/edge con metadata completa
```

#### 2. AI Service Directo
```bash
# PredicciÃ³n directa en AI Service
curl -X POST http://localhost:8000/ia/predict \
  -H "Content-Type: application/json" \
  -d '{
    "entrada": "Tarea importante para revisar",
    "modelo": "modelo_avanzado"
  }'

# Ver estadÃ­sticas del servicio
curl http://localhost:8000/ia/stats

# Listar modelos disponibles
curl http://localhost:8000/ia/models

# Health check AI Service
curl http://localhost:8000/ia/health
```

#### 3. Monitoreo y Estado
```bash
# Ver estado de contenedores
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# Ver logs en tiempo real
docker logs -f hybrid-ai-architecture-orchestration-service-1
docker logs -f hybrid-ai-architecture-ai-service-1

# Verificar Redis
docker exec hybrid-ai-architecture-redis-1 redis-cli ping
```

### Ejemplo de Respuesta de OrquestaciÃ³n

```json
{
  "resultado": {
    "prediction": "alta",
    "model_used": "modelo_edge",
    "inference_time_ms": 9.63,
    "confidence": 0.85,
    "source": "edge"
  },
  "metadata": {
    "request_id": "req_1757893202680_o3l0k5euf",
    "motor_usado": "edge",
    "modelo_usado": "modelo_edge",
    "contexto_evaluado": {
      "latencia_requerida": 92.48,
      "edge_disponible": true,
      "carga_sistema": 0.82,
      "prioridad": "alta",
      "datos_sensibles": false
    },
    "decision_info": {
      "motor_seleccionado": "edge",
      "razon": "Baja latencia requerida. Alta carga en cloud.",
      "confianza_decision": 0.75
    }
  },
  "mensaje": "Tarea procesada con edge (modelo_edge)"
}
```

### ValidaciÃ³n de CaracterÃ­sticas

âœ… **OrquestaciÃ³n DinÃ¡mica**: SelecciÃ³n automÃ¡tica edge vs cloud basada en contexto  
âœ… **Zero Trust AI**: ValidaciÃ³n de entrada con sanitizaciÃ³n  
âœ… **MÃºltiples Modelos**: 3 modelos disponibles (bÃ¡sico, avanzado, edge)  
âœ… **Logging Estructurado**: Request IDs Ãºnicos y trazabilidad completa  
âœ… **MÃ©tricas de Performance**: Tiempos de inferencia y estadÃ­sticas  
âœ… **ContainerizaciÃ³n**: Docker Compose funcional con hot-reload  
âœ… **API Documentation**: Swagger UI en http://localhost:8000/docs  

### Casos de Prueba EspecÃ­ficos

```bash
# Caso 1: Datos sensibles (deberÃ­a ir a edge)
curl -X POST http://localhost:3000/procesar-tarea \
  -H "Content-Type: application/json" \
  -d '{"entrada": "InformaciÃ³n personal confidencial", "contexto": "Datos privados"}'

# Caso 2: Baja prioridad (deberÃ­a ir a edge por eficiencia)
curl -X POST http://localhost:3000/procesar-tarea \
  -H "Content-Type: application/json" \
  -d '{"entrada": "Tarea de rutina", "contexto": "Procesamiento normal"}'

# Caso 3: Alta prioridad (puede ir a cloud por recursos)
curl -X POST http://localhost:3000/procesar-tarea \
  -H "Content-Type: application/json" \
  -d '{"entrada": "Emergencia crÃ­tica urgente", "contexto": "MÃ¡xima prioridad"}'
```

## ğŸ›ï¸ Arquitectura Detallada

### Flujo de Procesamiento

1. **Cliente** â†’ `POST /procesar-tarea` â†’ **Orchestration Service**
2. **Orchestration Service** evalÃºa contexto operativo
3. DecisiÃ³n dinÃ¡mica: **Cloud AI Service** vs **Edge Agent**
4. Procesamiento con modelo seleccionado
5. AplicaciÃ³n de reglas de negocio
6. Respuesta estructurada al cliente

### Factores de OrquestaciÃ³n

- **Latencia requerida** (< 100ms â†’ Edge preferido)
- **Disponibilidad de Edge** (Edge disponible/no disponible)
- **Carga del sistema Cloud** (> 80% â†’ Edge preferido)
- **Prioridad de tarea** (Alta â†’ Cloud, Media/Baja â†’ Edge)
- **Datos sensibles** (Sensibles â†’ Edge local)

### Modelos Disponibles

- `modelo_basico`: ClasificaciÃ³n simple de prioridad
- `modelo_avanzado`: ClasificaciÃ³n avanzada con mÃ¡s categorÃ­as
- `modelo_edge`: Optimizado para edge (rÃ¡pido y eficiente)

## ğŸ”’ Seguridad (Zero Trust AI)

- **ValidaciÃ³n de entrada**: SanitizaciÃ³n y verificaciÃ³n de caracteres
- **DetecciÃ³n de datos sensibles**: IdentificaciÃ³n automÃ¡tica
- **Procesamiento local**: Datos sensibles procesados en edge
- **Logging de seguridad**: AuditorÃ­a completa de decisiones
- **LÃ­mites de recursos**: PrevenciÃ³n de ataques DoS

## ğŸ“ Estructura del Proyecto

```
hybrid-ai-architecture/
â”œâ”€â”€ ai_service/                 # Microservicio de IA (FastAPI)
â”‚   â”œâ”€â”€ src/app/
â”‚   â”‚   â”œâ”€â”€ api/endpoints.py    # Endpoints REST
â”‚   â”‚   â”œâ”€â”€ inference/predictor.py  # LÃ³gica de modelos
â”‚   â”‚   â”œâ”€â”€ schemas/input_schema.py # ValidaciÃ³n Pydantic
â”‚   â”‚   â””â”€â”€ main.py            # AplicaciÃ³n FastAPI
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ orchestration_service/      # Servicio de orquestaciÃ³n (NestJS)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controllers/       # Controladores REST
â”‚   â”‚   â”œâ”€â”€ services/          # LÃ³gica de orquestaciÃ³n
â”‚   â”‚   â””â”€â”€ ai-client/         # Cliente HTTP para AI Service
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ edge_agent/                # Agente edge (FastAPI)
â”‚   â”œâ”€â”€ src/app/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ docker-compose.yml         # ConfiguraciÃ³n producciÃ³n
â”œâ”€â”€ docker-compose.dev.yml     # ConfiguraciÃ³n desarrollo
â”œâ”€â”€ .env.example              # Variables de entorno ejemplo
â””â”€â”€ README.md                 # Este archivo
```

## ğŸš§ PrÃ³ximas Extensiones (Roadmap)

### Fase 1: ComunicaciÃ³n AsÃ­ncrona
- [ ] **WebSockets/Events**: Implementar comunicaciÃ³n asÃ­ncrona real-time
- [ ] **Message Queues**: Redis Pub/Sub para eventos entre servicios
- [ ] **Event-Driven Architecture**: Patrones reactivos para alta concurrencia

### Fase 2: Aprendizaje AutÃ³nomo
- [ ] **MÃ©tricas de Performance**: Sistema de evaluaciÃ³n continua de modelos
- [ ] **Reentrenamiento AutomÃ¡tico**: Trigger automÃ¡tico basado en degradaciÃ³n
- [ ] **A/B Testing**: ComparaciÃ³n automÃ¡tica entre modelos
- [ ] **Feedback Loop**: IncorporaciÃ³n de feedback de usuarios

### Fase 3: Gobernanza Avanzada
- [ ] **Model Registry**: Versionado y lineage de modelos
- [ ] **Lifecycle Management**: PromociÃ³n automÃ¡tica devâ†’stagingâ†’prod
- [ ] **Compliance**: AuditorÃ­a y trazabilidad completa
- [ ] **Rollback**: ReversiÃ³n automÃ¡tica ante fallos

### Fase 4: IntegraciÃ³n ML Real
- [ ] **scikit-learn**: IntegraciÃ³n con modelos tradicionales
- [ ] **HuggingFace**: Soporte para transformers y LLMs
- [ ] **TensorFlow/PyTorch**: Modelos de deep learning
- [ ] **MLflow**: Tracking de experimentos

### Fase 5: Observabilidad Avanzada
- [ ] **Dashboard Web**: Interfaz de monitoreo en tiempo real
- [ ] **Alertas Inteligentes**: Notificaciones basadas en anomalÃ­as
- [ ] **Performance Analytics**: AnÃ¡lisis predictivo de carga
- [ ] **Cost Optimization**: OptimizaciÃ³n automÃ¡tica de recursos

### Comandos para Continuar Desarrollo

```bash
# Levantar arquitectura base
colima start
docker-compose -f docker-compose.dev.yml up --build -d

# Verificar estado
docker ps
curl http://localhost:3000/procesar-tarea -X POST -H "Content-Type: application/json" -d '{"entrada": "test"}'

# Desarrollo con hot-reload activo
docker logs -f hybrid-ai-architecture-orchestration-service-1
docker logs -f hybrid-ai-architecture-ai-service-1

# Parar servicios
docker-compose -f docker-compose.dev.yml down
```

## ğŸ“š Referencias

- Paper: "Una Arquitectura HÃ­brida Extensible para Sistemas IA-Ready"
- Autor: Facundo Leonardo Chayle (UAI) & Antonela Tommasel (UNICEN-ISISTAN-CONICET)
- Repositorio: https://github.com/Facfac5000-git/hybrid-ai-architecture

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver `LICENSE` para mÃ¡s detalles.